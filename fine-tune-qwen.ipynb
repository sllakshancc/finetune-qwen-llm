{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83_3GPGhxY57"
   },
   "source": [
    "##1. Data Generation & Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfraKSxByBL9"
   },
   "source": [
    "###1.1. Data Loading and Preprocessing\n",
    "\n",
    "make sure to upload md and pdf files into `/data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FjXHjHKyDfQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    \"\"\"Loads and preprocesses Markdown and PDF files.\"\"\"\n",
    "    documents = []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        if filename.endswith(\".md\"):\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "                text = re.sub(r\"^[#\\s]+\", \"\", text, flags=re.MULTILINE)\n",
    "                documents.append({\"filename\": filename, \"text\": text})\n",
    "        elif filename.endswith(\".pdf\"):\n",
    "            try:\n",
    "                with open(filepath, \"rb\") as f:\n",
    "                    pdf_reader = PdfReader(f)\n",
    "                    text = \"\"\n",
    "                    for page in pdf_reader.pages:\n",
    "                        text += page.extract_text()\n",
    "                    # cleaning\n",
    "                    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "                    text = re.sub(r\" +\", \" \", text)\n",
    "                    documents.append({\"filename\": filename, \"text\": text})\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading PDF {filename}: {e}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "data_dir = \"data\"\n",
    "documents = load_and_preprocess_data(data_dir)\n",
    "# print(documents[0]['text'][:500]) # check a document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqxY2vVV0lk3"
   },
   "source": [
    "###1.2. Synthetic Data Generation (using Qwen2.5-3B-Instruct itself, initially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jh0ELrAO0pQ0"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "def generate_qa_pairs(documents, model_name=\"Qwen/Qwen2.5-3B-Instruct\", num_questions_per_doc=5):\n",
    "    \"\"\"Generates QA pairs using the base Qwen model.\"\"\"\n",
    "\n",
    "    generator = pipeline('text-generation', model=model_name, device=0)  # Use GPU if available\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    qa_pairs = []\n",
    "    for doc in documents:\n",
    "\n",
    "        text_chunks = [doc['text'][i:i+4096] for i in range(0, len(doc['text']), 4096)]\n",
    "\n",
    "        for chunk in text_chunks:\n",
    "            prompt = f\"\"\"\n",
    "            Context:\n",
    "            {chunk}\n",
    "\n",
    "            Based on the above context, generate {num_questions_per_doc} question and answer pairs.\n",
    "            Format them strictly as follows:\n",
    "\n",
    "            Q: [Question 1]\n",
    "            A: [Answer 1]\n",
    "\n",
    "            Q: [Question 2]\n",
    "            A: [Answer 2]\n",
    "\n",
    "            ...\n",
    "            \"\"\"\n",
    "\n",
    "            # Generate text using model\n",
    "            generated_text = generator(\n",
    "                prompt,\n",
    "                max_length=1024,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                temperature=0.7\n",
    "            )[0]['generated_text']\n",
    "\n",
    "\n",
    "            matches = re.findall(r\"Q: (.*?)\\nA: (.*?)(?=\\nQ:|\\Z)\", generated_text, re.DOTALL)\n",
    "            for question, answer in matches:\n",
    "                qa_pairs.append({\"question\": question.strip(), \"answer\": answer.strip(), \"source\": doc['filename']})\n",
    "    return qa_pairs\n",
    "\n",
    "\n",
    "initial_qa_pairs = generate_qa_pairs(documents, num_questions_per_doc=3)\n",
    "# print(initial_qa_pairs[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBpkmB1J1ITt"
   },
   "source": [
    "###1.3. Data Augmentation and Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8AhWD-k1VL1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il4khaCg1jTP"
   },
   "source": [
    "###1.4. Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHX6VMBI1mCE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB7ZnTiy2tze"
   },
   "source": [
    "###1.5 Dataset Formatting (JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKHz3ePj2yK9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNxrpTNK3MWY"
   },
   "source": [
    "##2. Model Selection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeFOthn53QWH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhvWmsQE3iEn"
   },
   "source": [
    "##3. Efficient Fine-tuning (QLoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_h6G-EU3kZu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDnwmbOK3nJs"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5JLxfDcMw9zImAofRWJLB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
